 %!TEX root = ../elaboration.tex
\chapter{Results}
\label{cha:results}

\epigraph{This chapter will present the results of the implemented system, divided in two main sections. The first will analyse the quality and availability of the data collected by the \gls{IMU} Sensors, and the second will analyse the performance of the game metrics, described in Section~\ref{sec:metrics}.}

\section{Data Availability and Quality}
\label{sec:resultsData}
The evaluation of the data will be separated in two parts: the availability and the quality of the data.
The availability will measure if all the raw data sent by the \gls{IMU} Sensors is received by the Raspberry Pi's, and what factors affect it.
The quality will measure the degree of truthfulness of the raw data measured by the \gls{IMU} Sensors.

\subsection{Data Availability}
To measure the availability of data, it is retrieved from the \gls{IMU} Sensors, at 50Hz, from the accelerometer and gyroscope. No computations are made on the data. This means that the Raspberry Pi should receive 50 samples of Raw Data in 1 second. Measuring how many samples are missing, we can calculate the percentage of lost samples.

This measurements will be made in an open space, changing 3 factors: the Raspberry Pi version (3B+ vs 4); the distance between the Raspberry Pi and the \gls{IMU} Sensors; the number of \gls{IMU} Sensors.

The results from the different versions of the Raspberry Pi are displayed in Figures \ref{fig:datalossrPi3} and \ref{fig:datalossrPi4}. Between the two versions there is a big discrepancy in the percentage of samples lost, right from the closest distance. While Raspberry Pi 3B+ presents values between 5 and 10 percent, Raspberry Pi 4 has values between 0 and 1 percent. From there, every distance has a higher sample loss registered in Raspberry Pi 3B+ than in Raspberry Pi 4. This has to do with the introduction of the new version of Bluetooth 5.0 in the newer version of the Raspberry Pi.

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{PacketLoss(RaspberryPi3).pdf}
    \caption{Percentage of data loss (Raspberry Pi 3B+)}
    \label{fig:datalossrPi3}
\end{figure}

Increasing the number of devices doesn't seem to correlate with a bigger sample loss. Even though sometimes the highest number of devices has the higher percentage of lost samples, that doesn't always verifies.

However, increasing the distance increases, in the vast majority of the cases, the percentage of samples lost. In both graphs we see an increasing trend, no matter the version of the Raspberry Pi used or the number of devices connected.

There are some outliers, like the sudden decrease at 12 meters in Figure~\ref{fig:datalossrPi3}, or the peak of percentage of lost samples using 1 device, at 9 meters, in Figure~\ref{fig:datalossrPi4}. These could be caused by other bluetooth devices in the proximity, or other sources of noise, or the unreliable quality of the sensors.

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{PacketLoss(RaspberryPi4).pdf}
    \caption{Percentage of data loss (Raspberry Pi 4)}
    \label{fig:datalossrPi4}
\end{figure}

\subsection{Data Quality}

Regarding data quality, the raw data from a still sensor in a leveled surface will be analysed. Tables \ref{tab:qualexample1} and \ref{tab:qualexample2} show two examples of the first 20 samples collected from two different sensors, both placed side by side, in a plane surface. The rest of the samples where omitted, since these are enough to illustrate the big picture.

As we can see by comparing the first row with the remaining, the values are quite different. This might be caused by residual values left by the previous session. This data should be discarded, as it doesn't correspond to reality.

Ignoring the first row, the data we see is very noisy. The sensors aren't moving, yet the gyroscope shows significant values in the $X$ axis of Table~\ref{tab:qualexample1} and $X$ and $Y$ axis of Table~\ref{tab:qualexample2}. With a still device, these values should be zero, or close to zero. The $Z$ axis of the gyroscope in Table~\ref{tab:qualexample1} is the one that is closest to being zero.

In the accelerometer, the only axis that should have some value other than zero should be the z axis, and it should be the value of the force of gravity ($\approx 9,8 m/s^2$ ). In the examples, the values are lower than what they should be, and there is acceleration in the x and y axis, when there should be none, as the sensors are in a leveled surface. This may happen due to incorrect internal placement of the sensor inside its housing, leading to incorrect readings when the housing is leveled.

One way of correcting these errors is by removing the bias of the gyroscope values. This can be done by collecting data from each axis of the gyroscope, while the \gls{IMU} sensor is still, and to average the values of each axis. This gives the average bias. Then, for each sample, this calculated average bias should be subtracted from the gyroscope readings.

\begin{table}[]
    \centering
    \caption{Data Quality Example 1}
    \label{tab:qualexample1}
    \begin{tabular}{lllllll}
        \textbf{time} & \textbf{accX}    & \textbf{accY}     & \textbf{accZ}    & \textbf{gyrX}    & \textbf{gyrY}    & \textbf{gyrZ}     \\\cline{1-7}
        0,02    & -4,16082 & -1,82440 & 8,18885 & 0,19548 & -0,11718 & -0,08842 \\
        0,04    & 0,68071  & -0,42111 & 9,64837 & 0,16725 & -0,07457 & -0,01704 \\
        0,06    & 0,69985  & -0,43666 & 9,64238 & 0,16778 & -0,07404 & -0,01704 \\
        0,08    & 0,70224  & -0,47135 & 9,64597 & 0,16832 & -0,07457 & -0,01651 \\
        0,10    & 0,69028  & -0,43905 & 9,64597 & 0,16725 & -0,07564 & -0,01545 \\
        0,12    & 0,68669  & -0,45101 & 9,63521 & 0,16991 & -0,07564 & -0,01545 \\
        0,14    & 0,70224  & -0,44743 & 9,61965 & 0,16672 & -0,07457 & -0,01651 \\
        0,16    & 0,68071  & -0,44743 & 9,64358 & 0,16778 & -0,07617 & -0,01545 \\
        0,18    & 0,69148  & -0,47374 & 9,62205 & 0,16619 & -0,07457 & -0,01758 \\
        0,20    & 0,69507  & -0,44025 & 9,62683 & 0,16725 & -0,07510 & -0,01598
    \end{tabular}
\end{table}

\begin{table}[]
    \centering
    \caption{Data Quality Example 2}
    \label{tab:qualexample2}
    \begin{tabular}{lllllll}
        \textbf{time} & \textbf{accX}    & \textbf{accY}     & \textbf{accZ}    & \textbf{gyrX}    & \textbf{gyrY}    & \textbf{gyrZ}     \\\cline{1-7}
        0,02    & -5,80936 & -2,53741 & 8,16612 & 0,17844 & -0,25194 & -0,07617 \\
        0,04    & -0,99295 & -0,16868 & 9,77996 & 0,14009 & -0,29882 & -0,03569 \\
        0,06    & -0,98338 & -0,13758 & 9,75723 & 0,14328 & -0,30041 & -0,03622 \\
        0,08    & -0,98936 & -0,16868 & 9,74288 & 0,14115 & -0,30041 & -0,03462 \\
        0,10    & -0,98697 & -0,16509 & 9,73211 & 0,14168 & -0,29988 & -0,03569 \\
        0,12    & -0,99175 & -0,14954 & 9,77159 & 0,14168 & -0,30095 & -0,03622 \\
        0,14    & -0,99056 & -0,17107 & 9,76919 & 0,14115 & -0,29988 & -0,03569 \\
        0,16    & -0,99534 & -0,15791 & 9,75125 & 0,14115 & -0,30148 & -0,03622 \\
        0,18    & -0,98218 & -0,16390 & 9,77039 & 0,14328 & -0,30041 & -0,03729 \\
        0,20    & -0,99534 & -0,16509 & 9,74288 & 0,14062 & -0,29882 & -0,03515
    \end{tabular}
\end{table}


\section{Metrics Performance}
\label{sec:resultsMetrics}
\subsection{Position Tracking and Distance}
\label{subsec:positionresults}
%TODO falar que este algoritmo deu bons resultados quando apenas se andava, mas não é mmuito fiável a correr. 
%TODO a distância era bastante mais alta que a trajetória real pecorrida
%TODO algoritmo não é em tempo real, demora algum tempo a  calcular resultados
Position tracking and distance were tested by using a sensor placed in the foot, above the shoe, as detailed in Subsection~\ref{subsubsec:trajectories}.

Firstly, the calculation of distance was put to the test. The distance is calculated by measuring the distance between each coordinate, using the Euclidean distance. The first test performed was to find what was the distance calculated when the sensor was still. Figure~\ref{fig:stillDistance} shows the plot of data collected during 30 seconds, while the foot was still. As we can see, the displacement is very low, and the distance calculated is in the order of the millimeters.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{stillDistance.pdf}
    \caption{Still Distance Plot}
    \label{fig:stillDistance}
\end{figure}

The second thing to test was the actual measurements of distance, compared to the real walked distance. For this, two sensors were worn, one in each foot, to compare the measurements between the two. It was asked to the subject to walk in a straight line, with varying distances: 6 meters, 12 meters and 18 meters.
Figures \ref{fig:direitoStill} and \ref{fig:esquerdoStill} show the plot of the 3 distances, with data collected from the right and the left foot, respectively. The right foot presents calculated distances of 6.94m, 13.69m and 23.35m, and the left foot presents distances of 7.09m, 15.15m and 22.00m.
As we can see by the plot, the further the subject walks, the greater the error of the calculated distance. This has to do with the accumulated error of the sensor values. These errors are originated in gyroscope noise, and are then propagated through the heading and speed estimations, affecting the position estimations. The error in position estimation affects directly the distance calculation.

\begin{figure}[htbp]
    \centering
    \subcaptionbox{Right Foot - 6m\label{fig:direito6}}%
    {\includegraphics[width=0.33\linewidth]{peDireito6m.pdf}}%
    \subcaptionbox{Right Foot - 12m\label{fig:direito12}}%
    {\includegraphics[width=0.33\linewidth]{peDireito12m.pdf}}%
    \subcaptionbox{Right Foot - 18m\label{fig:direito18}}%
    {\includegraphics[width=0.33\linewidth]{peDireito18m.pdf}}%
    \caption{Right foot - Still}
    \label{fig:direitoStill}
\end{figure}

\begin{figure}[htbp]
    \centering
    \subcaptionbox{Left Foot - 6m\label{fig:esquerdo6}}%
    {\includegraphics[width=0.33\linewidth]{peEsquerdo6m.pdf}}%
    \subcaptionbox{Left  Foot - 12m\label{fig:esquerdo12}}%
    {\includegraphics[width=0.33\linewidth]{peEsquerdo12m.pdf}}%
    \subcaptionbox{Left  Foot - 18m\label{fig:esquerdo18}}%
    {\includegraphics[width=0.33\linewidth]{peEsquerdo18m.pdf}}%
    \caption{Left foot - Still}
    \label{fig:esquerdoStill}
\end{figure}

Secondly, the tracking of the subject position was tested. In this test, more complex routes were followed, and the subjects were asked not only to walk, but also to run, to test the response of the tracking algorithm.

The first test was to walk in a straight line and doing 90$^{\circ}$ right turns, in the office corridors. The route is illustrated in Figure~\ref{fig:caracolRoute}.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{caracolOriginal.pdf}
    \caption{Positional Tracking First Test Route}
    \label{fig:caracolRoute}
\end{figure}

As we can see in Figure~\ref{fig:caracol}, the distance, that should sum up to 65 meters, was calculated as being 90 meters. The positional tracking of the subject also presents some deviations, especially right at the beginning. The subject was asked to stand still for a moment before he started walking, so that the sensor could be at rest. However, instead of plotting the route to the front as a straight line (which would correspond to reality), it plotted an angled line. Consequently, all the route was tilted. On the other hand, even though this initial detour, all the following turns seem to match the reality, showing the 90$^{\circ}$ turns made by the subject. 
\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{Caracol.pdf}
    \caption{Positional Tracking First Test}
    \label{fig:caracol}
\end{figure}
The second test consisted in performing the route illustrated in Figure~\ref{fig:uoriginal}, while walking and then performing a mix of both: start the route walking, and after the turn, start running, to see how the algorithm performed.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{uOriginal.pdf}
    \caption{Positional Tracking Second Test Route}
    \label{fig:uoriginal}
\end{figure}

In the first example, illustrated in Figure~\ref{fig:uoriginalAndar}, we can see the deviation of the algorithm, after about 10m, but the turns are well traced, and the second straight line is also well traced. If it wasn't for the detour, the plot would be near perfect.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{uOriginal+andar.pdf}
    \caption{Positional Tracking Second Test - Walking}
    \label{fig:uoriginalAndar}
\end{figure}

In the second example, illustrated in Figure~\ref{fig:uoriginalAndarCorrer}, even though the first part of the route shows a well traced straight line and turn, when the run started (after the turn), the algorithm couldn't identify well the movement. The tracing is very imprecise, and the last turn wasn't identified. 

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{uOriginal+andarCorrer.pdf}
    \caption{Positional Tracking Second Test - Walking and Running}
    \label{fig:uoriginalAndarCorrer}
\end{figure}

This might be due to two factors: the rate at which data is being collected (50Hz) might be insufficient to detect a fast movement such as running, or the movements produced by a running activity might be out of the range of the accelerometer, which was set for -8g to +8g.

Basketball players spent most of their running, so the difficulty of this algorithm to recognize running movements is a drawback. However, this algorithm is promising and did provide good results when walking, and some tweaks in the algorithm could be applied in the future in order to improve the positional tracking of a subject when he is running. 

\subsection{Steps}
For testing the Step counting algorithm, it was asked to 3 subjects to walk and run in a straight line, taking varying numbers of steps. As the sensor is placed in the right foot, the algorithm only detects half of the steps (the steps taken with the right foot). Therefore, to obtain the total amount of steps, the result calculated by the algorithm should be multiplied by two, taking into account that the doubled value can be off by one step (\textit{i.e.} if the movement started with the right foot, and 5 steps were given in total, ending with the right foot, the sensor placed in the right foot would register 3 steps. Doubling this value, we would have a total of 6 steps, which is wrong by one step.)

Figure \ref{fig:stepDetection} shows the results of the tests performed by the subjects. The blue bars show the number of steps taken while walking, and the green bars show the numbers of steps taken while running, in each session. The red area represents the number of steps detected. The percentage values are the percentage of correct step detections, performed by the algorithm.

As we can see, the algorithm performs very well, detecting all the steps taken by the foot where the sensor was placed, even when running. As discussed in Subsection~\ref{subsec:steps}, there is still place for improving the algorithm, but the results with the current version are very satisfying.

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{stepDetection.pdf}
    \caption{Step Detection}
    \label{fig:stepDetection}
\end{figure}

\subsection{Dribbles}
To test the dribble detection algorithm algorithm described in Subsection~\ref{subsec:dribbles}, it was asked to five subjects to perform a set of 20 dribbles, at three different speeds: slow ($\approx$90 dribbles per minute), medium ($\approx$120 dribbles per minute) and fast ($\approx$160 dribbles per minute). The dribbles were all performed in-place.

Figure~\ref{fig:dribbledetection} shows the percentage of correct number of dribble detections achieved by this algorithm. Each bar represents the number of dribbles performed by each subject, and the colors represent the speed of the dribbling: yellow for slow, green for medium and blue for fast. The red area represents the number of dribbles detected by the algorithm, and the percentage of correctly detected dribbles is shown in the bottom of each column, as a percentage.

The dribble detection algorithm can be wrong if it detects less or more dribbles than those that were really performed. The case of detecting more dribbles was only verified when dribbling fast.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{dribbleDetection.pdf}
    \caption{Dribble Detection}
    \label{fig:dribbledetection}
\end{figure}

By analyzing the results, we can see that slow dribbling had the worst results of all three. The most likely cause of this bigger error might be the frequency threshold to confirm that the movement is a dribble. However, if this threshold is lowered, simple arm or wrist movements could be identified as a dribble movement. A compromise must be made, between detecting all the dribble movements, but also detect wrong random movements, or to discard slow dribbling movements, but ensure that other arm movements aren't identified as dribbles. The latter approach was selected.

Identifying medium and fast dribbling achieved better results, with a percentage of correct dribble detections always between 90\% and 100\%.
In fast dribbling, the algorithm would sometimes detect more dribbles than those that were actually made, and in medium dribbling, the algorithm would detect one or two less dribbles than those that were actually made, maybe because of different hand movement when starting or stopping the movement.

\subsection{Jumps}
%Os saltos têm de ter mais de 30cm, porque o algoritmo apenas deteta estes, se não confundia com corrida
To collect jump data for the results phase, it was asked to three subjects to perform sets of ten jumps, with a rest of 1 or 2 seconds between each jump. The jumps were either done vertically, or with a small displacement to the front. The sensor was placed in the lower back of each subject, held in place with the help of an abdominal binder.

In Figure~\ref{fig:jumpdetection} we can see the results of the data collected. The blue bars show the number of jumps performed in each session, and the red area represents the number of jumps detected. The percentage values are the percentage of correct jump detections, performed by the algorithm. The average of the correct detections of this algorithm is 17\% percent. This is value is very low and unsatisfactory. 

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{jumpDetection.pdf}
    \caption{Jump Detection}
    \label{fig:jumpdetection}
\end{figure}

However, while collecting data, some particularities of the algorithm where detected, and could be improved in the future. For example, when two similar jumps were performed, with a rest time of about 2 seconds between them, sometimes the algorithm detected zero jumps, and sometimes it only detects one jump, but never the two jumps that were really performed.
This may have to do with the reset parameters of the algorithm not being well adjusted. This means that the algorithm is not identifying correctly the moment when the subject is at rest, thus not detecting all the jumps.

Another problem is the threshold from which the algorithm detects jumps. This threshold was set in development phase to separate running movements from jumps. As the jump is a slower movement than running, its frequency is also lower. While developing, the value set looked good, but when tested with other subjects, and after analyzing the results, we can conclude that the value can be increased, to detect more jumps. A drawback of this increase is the detection of unwanted movements, but it might be necessary, taking into account the poor performance of this algorithm. %silver lining