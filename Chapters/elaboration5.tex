%!TEX root = ../elaboration.tex
\chapter{Results}
\label{cha:results}

\epigraph{This chapter will present the results of the implemented system, divided in two main sections. The first will analyse the quality and availability of the data collected by the \gls{IMU} Sensors, and the second will analyse the performance of the game metrics, described in Section~\ref{sec:metrics}.}

\section{Data Availability and Quality}
\label{sec:resultsData}
The evaluation of the data will be separated in two parts: the availability and the quality of the data.
The availability will measure if all the raw data sent by the \gls{IMU} Sensors is received by the Raspberry Pi's, and what factors affect it.
The quality will measure the degree of truthfulness of the raw data measured by the \gls{IMU} Sensors.

\subsection{Data Availability}
To measure the availability of data, it is retrieved from the \gls{IMU} Sensors, at 50Hz, from the accelerometer and gyroscope. No computations are made on the data. This means that the Raspberry Pi should receive 50 samples of Raw Data in 1 second. Measuring how many samples are missing, we can calculate the percentage of lost samples.

This measurements will be made in an open space, changing 3 factors: the Raspberry Pi version (3B+ vs 4); the distance between the Raspberry Pi and the \gls{IMU} Sensors; the number of \gls{IMU} Sensors.

The results from the different versions of the Raspberry Pi are displayed in Figures \ref{fig:datalossrPi3} and \ref{fig:datalossrPi4}. Between the two versions there is a big discrepancy in the percentage of samples lost, right from the closest distance. While Raspberry Pi 3B+ presents values between 5 and 10 percent, Raspberry Pi 4 has values between 0 and 1 percent. From there, every distance has a higher sample loss registered in Raspberry Pi 3B+ than in Raspberry Pi 4. This has to do with the introduction of the new version of Bluetooth 5.0 in the newer version of the Raspberry Pi.

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{PacketLoss(RaspberryPi3).pdf}
    \caption{Percentage of data loss (Raspberry Pi 3B+)}
    \label{fig:datalossrPi3}
\end{figure}

Increasing the number of devices doesn't seem to correlate with a bigger sample loss. Even though sometimes the highest number of devices has the higher percentage of lost samples, that doesn't always verifies.

However, increasing the distance increases, in the vast majority of the cases, the percentage of samples lost. In both graphs we see an increasing trend, no matter the version of the Raspberry Pi used or the number of devices connected.

There are some outliers, like the sudden decrease at 12 meters in Figure~\ref{fig:datalossrPi3}, or the peak of percentage of lost samples using 1 device, at 9 meters, in Figure~\ref{fig:datalossrPi4}. These could be caused by other bluetooth devices in the proximity, or other sources of noise, or the unreliable quality of the sensors.

\begin{figure}
    \centering
    \includegraphics[width=.7\textwidth]{PacketLoss(RaspberryPi4).pdf}
    \caption{Percentage of data loss (Raspberry Pi 4)}
    \label{fig:datalossrPi4}
\end{figure}

\subsection{Data Quality}

Regarding data quality, the raw data from a still sensor in a leveled surface will be analysed. Tables \ref{tab:qualexample1} and \ref{tab:qualexample2} show two examples of the first 20 samples collected from two different sensors, both placed side by side, in a plane surface. The rest of the samples where omitted, since these are enough to illustrate the big picture.

As we can see by comparing the first row with the remaining, the values are quite different. This might be caused by residual values left by the previous session. This data should be discarded, as it doesn't correspond to reality.

Ignoring the first row, the data we see is very noisy. The sensors aren't moving, yet the gyroscope shows significant values in the $X$ axis of Table~\ref{tab:qualexample1} and $X$ and $Y$ axis of Table~\ref{tab:qualexample2}. With a still device, these values should be zero, or close to zero. The $Z$ axis of the gyroscope in Table~\ref{tab:qualexample1} is the one that is closest to being zero.

In the accelerometer, the only axis that should have some value other than zero should be the z axis, and it should be the value of the force of gravity ($\approx 9,8 m/s^2$ ). In the examples, the values are lower than what they should be, and there is acceleration in the x and y axis, when there should be none, as the sensors are in a leveled surface. This may happen due to incorrect internal placement of the sensor inside its housing, leading to incorrect readings when the housing is leveled.

One way of correcting these errors is by removing the bias of the gyroscope values. This can be done by collecting data from each axis of the gyroscope, while the \gls{IMU} sensor is still, and to average the values of each axis. This gives the average bias. Then, for each sample, this calculated average bias should be subtracted from the gyroscope readings.

\begin{table}[]
    \centering
    \caption{Data Quality Example 1}
    \label{tab:qualexample1}
    \begin{tabular}{lllllll}
        \textbf{time} & \textbf{accX}    & \textbf{accY}     & \textbf{accZ}    & \textbf{gyrX}    & \textbf{gyrY}    & \textbf{gyrZ}     \\\cline{1-7}
        0,02    & -4,16082 & -1,82440 & 8,18885 & 0,19548 & -0,11718 & -0,08842 \\
        0,04    & 0,68071  & -0,42111 & 9,64837 & 0,16725 & -0,07457 & -0,01704 \\
        0,06    & 0,69985  & -0,43666 & 9,64238 & 0,16778 & -0,07404 & -0,01704 \\
        0,08    & 0,70224  & -0,47135 & 9,64597 & 0,16832 & -0,07457 & -0,01651 \\
        0,10    & 0,69028  & -0,43905 & 9,64597 & 0,16725 & -0,07564 & -0,01545 \\
        0,12    & 0,68669  & -0,45101 & 9,63521 & 0,16991 & -0,07564 & -0,01545 \\
        0,14    & 0,70224  & -0,44743 & 9,61965 & 0,16672 & -0,07457 & -0,01651 \\
        0,16    & 0,68071  & -0,44743 & 9,64358 & 0,16778 & -0,07617 & -0,01545 \\
        0,18    & 0,69148  & -0,47374 & 9,62205 & 0,16619 & -0,07457 & -0,01758 \\
        0,20    & 0,69507  & -0,44025 & 9,62683 & 0,16725 & -0,07510 & -0,01598
    \end{tabular}
\end{table}

\begin{table}[]
    \centering
    \caption{Data Quality Example 2}
    \label{tab:qualexample2}
    \begin{tabular}{lllllll}
        \textbf{time} & \textbf{accX}    & \textbf{accY}     & \textbf{accZ}    & \textbf{gyrX}    & \textbf{gyrY}    & \textbf{gyrZ}     \\\cline{1-7}
        0,02    & -5,80936 & -2,53741 & 8,16612 & 0,17844 & -0,25194 & -0,07617 \\
        0,04    & -0,99295 & -0,16868 & 9,77996 & 0,14009 & -0,29882 & -0,03569 \\
        0,06    & -0,98338 & -0,13758 & 9,75723 & 0,14328 & -0,30041 & -0,03622 \\
        0,08    & -0,98936 & -0,16868 & 9,74288 & 0,14115 & -0,30041 & -0,03462 \\
        0,10    & -0,98697 & -0,16509 & 9,73211 & 0,14168 & -0,29988 & -0,03569 \\
        0,12    & -0,99175 & -0,14954 & 9,77159 & 0,14168 & -0,30095 & -0,03622 \\
        0,14    & -0,99056 & -0,17107 & 9,76919 & 0,14115 & -0,29988 & -0,03569 \\
        0,16    & -0,99534 & -0,15791 & 9,75125 & 0,14115 & -0,30148 & -0,03622 \\
        0,18    & -0,98218 & -0,16390 & 9,77039 & 0,14328 & -0,30041 & -0,03729 \\
        0,20    & -0,99534 & -0,16509 & 9,74288 & 0,14062 & -0,29882 & -0,03515
    \end{tabular}
\end{table}


\section{Metrics Performance}
\label{sec:resultsMetrics}
\subsection{Position Tracking and Distance}
%TODO falar que este algoritmo deu bons resultados quando apenas se andava, mas não é mmuito fiável a correr. 
%TODO a distância era bastante mais alta que a trajetória real pecorrida
%TODO algoritmo não é em tempo real, demora algum tempo a  calcular resultados

\subsection{Steps}

\subsection{Dribbles}
To test the dribble detection algorithm algorithm described in Subsection~\ref{subsec:dribbles}, it was asked to five subjects to perform a set of 20 dribbles, at three different speeds: slow ($\approx$90 dribbles per minute), medium ($\approx$120 dribbles per minute) and fast ($\approx$160 dribbles per minute). The dribbles were all performed in-place.

Figure~\ref{fig:dribbledetection} shows the percentage of correct number of dribble detections achieved by this algorithm. The dribble detection algorithm can be wrong if it detects less or more dribbles than those that were really performed. The case of detecting more dribbles was only verified when dribbling fast.

\begin{figure}
    \centering
    \includegraphics[width=.9\textwidth]{dribbledetection.pdf}
    \caption{Dribble Detection}
    \label{fig:dribbledetection}
\end{figure}

By analyzing the results, we can see that slow dribbling had the worst results of all three. The most likely cause of this bigger error might be the frequency threshold to confirm that the movement is a dribble. However, if this threshold is lowered, simple arm or wrist movements could be identified as a dribble movement. A compromise must be made, between detecting all the dribble movements, but also detect wrong random movements, or to discard slow dribbling movements, but ensure that other arm movements aren't identified as dribbles. The latter approach was selected.

Identifying medium and fast dribbling achieved better results, with a percentage of correct dribble detections always between 95\% and 100\%.
The biggest error in these two movements occurred in the fast dribbles, where the algorithm would sometimes detect more dribbles than those that were actually made, and in both movements, where the algorithm would detect one less dribble, maybe because of different hand movement when starting or stopping the movement.

\subsection{Jumps}
%Os saltos têm de ter mais de 30cm, porque o algoritmo apenas deteta estes, se não confundia com corrida
To collect jump data for the results phase, it was asked to three subjects to perform sets of ten jumps, with a rest of 1 or 2 seconds between each jump. The jumps were either done vertically, or with a small displacement to the front. The sensor was placed in the lower back of each subject, held in place with the help of an abdominal binder.

In Figure~\ref{fig:jumpdetection} we can see the results of the data collected. The blue bars show the number of jumps performed in each session, and the red line represents the number of jumps detected. The percentage values are the percentage of correct jump detections, performed by the algorithm. The average of the correct detections of this algorithm is 17\% percent. This is value is very low and unsatisfactory. 

\begin{figure}
    \centering
    \includegraphics[width=.9\textwidth]{jumpDetection.pdf}
    \caption{Jump Detection}
    \label{fig:jumpdetection}
\end{figure}

However, while collecting data, some particularities of the algorithm where detected, and could be improved in the future. For example, when two similar jumps were performed, with a rest time of about 2 seconds between them, sometimes the algorithm detected zero jumps, and sometimes it only detects one jump, but never the two jumps that were really performed.
This may have to do with the reset parameters of the algorithm not being well adjusted. This means that the algorithm is not identifying correctly the moment when the subject is at rest, thus not detecting all the jumps.

Another problem is the threshold from which the algorithm detects jumps. This threshold was set in development phase to separate running movements from jumps. As the jump is a slower movement than running, its frequency is also lower. While developing, the value set looked good, but when tested with other subjects, and after analyzing the results, we can conclude that the value can be increased, to detect more jumps. A drawback of this increase is the detection of unwanted movements, but it might be necessary, taking into account the poor performance of this algorithm. %silver lining